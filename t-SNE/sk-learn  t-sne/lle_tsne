在数字数据集上不同的嵌入的描述

RandomTreesEmbedding从sklearn.ensemble模块中，在技术上不是一个流形嵌入方法，因为它学习了一个高维表示，我们应用了一个降维方法。
然而，把一个数据集转换成一个类可以线性分离的表示通常是有用的。

tsne的嵌入初始化在这个例子中是由PCA生产的，并不是默认操作，它保证了全局嵌入的稳定性。例如，嵌入并没有依赖全局初始化

Embedding在数学上表示一个maping,也就是一个function。就是降维。
其中该函数满足两个性质：injective （单射的）：就是我们所说的单射函数，每个Y只有唯一的X对应;
structure-preserving（结构保存）：比如在X所属的空间上x1<x2，那么映射后在Y所属空间上同理y1<y2。
那么对于word embedding, 就是找到一个映射(函数)将单词(word)映射到另外一个空间(其中这个映射具有injective和structure-preserving的特点),
生成在一个新的空间上的表达，该表达就是word representation.

流形学习
传统的机器学习方法中，数据点和数据点之间的距离和映射函数f都是定义在欧式空间中的，然而在实际情况中，这些数据点可能不是分布在欧式空间中的，
因此传统欧式空间的度量难以用于真实世界的非线性数据，从而需要对数据的分布引入新的假设。

流形(Manifold)是局部具有欧式空间性质的空间，包括各种纬度的曲线曲面，例如球体、弯曲的平面等。流形的局部和欧式空间是同构的。

流形学习假设所处理的数据点分布在嵌入于外维欧式空间的一个潜在的流形体上，或者说这些数据点可以构成这样一个潜在的流形体。

假设数据是均匀采样于一个高维欧氏空间中的低维流形，流形学习就是从高维采样数据中恢复低维流形结构，即找到高维空间中的低维流形，并求出相应的嵌入映射，
以实现维数约简或者数据可视化。它是从观测到的现象中去寻找事物的本质，找到产生数据的内在规律